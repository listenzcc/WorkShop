\documentclass[../concepts.tex]{subfiles}

\begin{document}
\subsubsection{Explain of Lemma\ref{Lemma: Variance of mean value}}
\textbf{Variance of mean value}
% ---------------------------------------
%    Original contents
\begin{quote}
    The variance of mean value equals to the mean of all covariance terms
    \begin{equation*}
        \mathcal{V}(\overline{X}) =
        \frac{1}{n^2} \sum_{i, j} Cov(X_i, X_j),
        i, j \in 1, 2, \dots, n
    \end{equation*}
    no matter the relationship between the statistics of $X_1, X_2, \dots, X_n$.
\end{quote}
% ---------------------------------------

% ---------------------------------------
%    Your word goes here

The variance of mean value equals to the mean of all covariance terms
\begin{equation*}
    \mathcal{V}(\overline{X}) =
    \frac{1}{n^2} \sum_{i, j} Cov(X_i, X_j),
    i, j \in 1, 2, \dots, n
\end{equation*}
no matter the relationship between the statistics of $X_1, X_2, \dots, X_n$.


Prove that, the variance of mean value equals to the mean of all covariance terms
\begin{equation*}
    \mathcal{V}(\overline{X}) =
    \frac{1}{n^2} \sum_{i, j} Cov(X_i, X_j),
    i, j \in 1, 2, \dots, n
\end{equation*}
no matter the relationship between the statistics of $X_1, X_2, \dots, X_n$.

\begin{proof}
    The mean value of $n$ statistics can be expressed as
    \begin{equation*}
        \overline{X} = \frac{1}{n} \sum_{i} X_i,
        i \in 1, 2, \dots, n
    \end{equation*}

    Based on the definition, the variance can be expressed as
    \begin{align*}
        Var(\overline{X}) & =  \int_{X_1, X_2, \dots, X_n} {\overline{x}}^2 p(x_1, x_2, \dots, x_n) dx_1 x_2 \dots x_n \\
                          & - (\int_{X_1, X_2, \dots, X_n} \overline{x} p(x_1, x_2, \dots, x_n) dx_1 x_2 \dots x_n)^2  \\
                          & , i, j \in 1, 2, \dots, n
    \end{align*}

    Use the property of full probability rules, we have
    \begin{align*}
         & \int_{X_k, \dots} f(x_k) \cdot p(x_k, \dots) dx_k \dots                    \\
         & = \int_{X_k} f(x_k) \cdot p(x_k) dx_k                                      \\
         & \int_{X_i, X_j, \dots} f(x_i, x_j) \cdot p(x_i, x_j, \dots) dx_i x_j \dots \\
         & = \int_{X_i, X_j} f(x_i, x_j) \cdot p(x_i, x_j) dx_i x_j
    \end{align*}

    Thus the variance of the mean value can be formulated as
    \begin{align*}
        n^2 \cdot Var(\overline{X}) & = \sum_i \int x_i^2 p(x_i) dx_i + \sum_{i \neq j} \int x_i x_j p(x_i, x_j) dx_i x_j \\
                                    & - (\sum_i \int x_i p(x_i) dx_i)^2
    \end{align*}
    since the positive and negative terms are both of $n^2$ terms.
    By pairing them one-by-one, we come to
    \begin{align*}
        n^2 \cdot Var(\overline{X}) & = \sum_{i, j} \mathcal{E}(X_i X_j) - \mathcal{E}(X_i)\mathcal{E}(X_j) \\
        Var(\overline{X})           & = \frac{1}{n^2} \sum_{i, j} Cov(X_i, X_j)
    \end{align*}

    Hence proved.
\end{proof}
% ---------------------------------------
\end{document}
