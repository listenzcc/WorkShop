
\documentclass[a4paper]{article}

\usepackage{amssymb}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}

\title{Basic of Distribution}
\author{listenzcc}

\begin{document}

\maketitle

\abstract
A collection of basic distribution knowledge.

\tableofcontents

\section{Pre-knowledge}

\subsection{Gamma function}

An infinity integer is called as \emph{Gamma ($\Gamma$) function}

\begin{equation}
    \Gamma(z) = \int_{0}^{\infty} x^{z-1} e^{-x} \,\mathrm{d}x
\end{equation}

\begin{proposition} \label{Gamma function propositions}
    Some very important equations.

    The value of $\Gamma(\frac{1}{2})$
    \begin{equation*}
        \Gamma(\frac{1}{2}) = \sqrt {\pi}
    \end{equation*}

    The recursive of $\Gamma(n)$, the general situation,
    \begin{equation*}
        \begin{aligned}
            \Gamma(1+z) & = z \Gamma(z)   \\
            \Gamma(1-z) & = -z \Gamma(-z)
        \end{aligned}
    \end{equation*}

    The integer situation,
    \begin{equation*}
        \Gamma(n) = (n-1)! \quad \forall n \in \mathcal{N}^+
    \end{equation*}

    The relationship between $\Gamma$ and $e^{x^{2}}$
    \begin{equation*}
        \Gamma(z) = 2 \int_{0}^{\infty} x^{2z-1} e^{x^{2}} \,\mathrm{d}x
    \end{equation*}

    The relationship between $\Gamma$ and Beta Function ($B(\alpha, \beta)$)
    \begin{equation*}
        \begin{aligned}
            B(\alpha, \beta) & = \frac{\Gamma(\alpha) \cdot \Gamma(\beta)}{\Gamma(\alpha + \beta)} \\
            B(\alpha, \beta) & = \int_{0}^{1} t^{\alpha-1} (1-t)^{\beta-1} \,\mathrm{d}t
        \end{aligned}
    \end{equation*}
    See \ref{The relationship between Gamma and Beta} for proof.

\end{proposition}

\section{Normal distribution}
\subsection{Definition}
It is hard to say normal distribution is what, since almost every thing follows it.

The Probability Distribution Function \emph{(pdf)} of normal distribution is
\begin{equation}
    p(x) = \frac{1}{\sqrt{2\pi}\delta} \exp({-\frac{(x-\mu)^2}{2\delta^2}}), -\infty < x < \infty
\end{equation}
the symbolic notion is $p(x) \sim N(\mu, \delta^2)$.
When $\mu = 0$ and $\delta^2 = 1$, it is called standard normal distribution.

\subsection{Mean and Variance}
The mean and variance of the normal distribution is
\begin{equation*}
    \begin{aligned}
        Mean     & \triangleq E(x) = \mu                 \\
        Variance & \triangleq E(x^2) - E^2(x) = \delta^2
    \end{aligned}
\end{equation*}
it is easy to proof using Proposition \ref{Gamma function propositions}.

\section{Chi-squared distribution}
\subsection{Definition}
If $Y_i \sim N(0, 1)$, then
\begin{equation}
    \chi^2 \equiv \sum_{i = 1}^{r} Y_i^2
\end{equation}
is distributed as Chi-squared \emph{$\chi^2$} distribution with $r$ degrees of freedom.
The symbolic notion is $p_r(x) \sim \chi^2(r)$.

The pdf of Chi-squared distribution is
\begin{equation}
    P_r(x) = \frac{x^{r/2-1} e^{-x/2}}{\Gamma(r/2) 2^{r/2}}, 0 < x < \infty
\end{equation}

\subsection{Mean and Variance}
The mean and variance of the chi-squared distribution is
\begin{equation*}
    \begin{aligned}
        Mean     & \triangleq E(x) = r             \\
        Variance & \triangleq E(x^2) - E^2(x) = 2r
    \end{aligned}
\end{equation*}
it is easy to proof using Proposition \ref{Gamma function propositions}.

\section{Student's t-distribution}
\subsection{Definition}
The probability distribution of a random variable $T$, of the form
\begin{equation*}
    T = \frac{\bar{x} - m}{s / \sqrt{N}}
\end{equation*}
where $\bar{x}$ is the sample mean value of all $N$ samples, $m$ is the population mean value and $s$ is the population standard deviation.

Or, in a more formal one
\begin{equation}
    T = \frac{X}{\sqrt{Y/r}}
\end{equation}
where $X \sim N(0, 1)$ and $Y \sim \chi_r^2$.

The pdf of Student's t-distribution is
\begin{equation}
    t_r(x) = \frac{\Gamma(\frac{r+1}{2})}{\Gamma(\frac{r}{2}) \sqrt{r\pi}} (1+\frac{x^2}{r})^{-\frac{r+1}{2}}, -\infty < x < \infty
\end{equation}
it is easy to proof the pdf is a pdf using \ref{The pdf of Student's t-distribution is a pdf}.

It is also easy to see that $\lim_{r \to \infty} t_r(x) \sim N(0, 1)$.
It is the relationship between Student's t-distribution and normal distribution.

\subsection{Mean and Variance}
The mean and variance of the Student's t-distribution is
\begin{equation*}
    \begin{aligned}
        Mean     & \triangleq E(x) = 0                        \\
        Variance & \triangleq E(x^2) - E^2(x) = \frac{r}{r-2}
    \end{aligned}
\end{equation*}

\appendix

\section{Appendix}

\subsection{The relationship between $\Gamma$ and $B(\alpha, \beta)$}
\begin{proof} \label{The relationship between Gamma and Beta}

    One can write
    \begin{equation*}
        \Gamma(m)\Gamma(n) = \int_{0}^{\infty} x^{m-1} e^{-x} dx \int_{0}^{\infty} y^{n-1} e^{-y} dy
    \end{equation*}
    Then rewrite it as a double integral
    \begin{equation*}
        \Gamma(m)\Gamma(n) = \int_{0}^{\infty} \int_{0}^{\infty} x^{m-1} y^{n-1} e^{-x-y} dx dy
    \end{equation*}
    Applying the substitution $x=vt$ and $y=v(1-t)$, we have
    \begin{equation*}
        \Gamma(m)\Gamma(n) = \int_{0}^{1} t^{m-1} (1-t)^{n-1} dt \int_{0}^{\infty} v^{m+n-1} e^{-v} dv
    \end{equation*}
    Using the definitions of $\Gamma$ and Beta functions, we have
    \begin{equation*}
        \Gamma(m)\Gamma(n) = B(m, n) \Gamma(m+n)
    \end{equation*}
    Hence proved.
\end{proof}

\begin{proof} \label{The pdf of Student's t-distribution is a pdf}
    Consider the variable part of Student's t-distribution
    \begin{equation*}
        f(x) = (1+\frac{x^2}{r})^{-\frac{r+1}{2}}, -\infty < x < \infty
    \end{equation*}
    use a replacement as following
    \begin{equation*}
        x^2 = \frac{y}{1-y}
    \end{equation*}
    it is easy to see that $\lim_{y \to 0} x = 0$ and $\lim_{y \to 1} x = \infty$.
    Additionally, the $x^2$ is even function.
    Thus we can write the integral of $f(x)$
    \begin{equation*}
        \int_{-\infty}^{\infty} f(x) \,\mathrm{d}x =
        2 \sqrt{r} \int_{0}^{1} (\frac{1}{1-y})^{-\frac{r+1}{2}} \,\mathrm{d} (\frac{y}{1-y})^\frac{1}{2}
    \end{equation*}
    it is not hard to find out that the integral may end up with
    \begin{equation*}
        \sqrt{r} \int_{0}^{1} (1-y)^{\frac{r}{2}-1} y^{\frac{1}{2}-1} \,\mathrm{d}y =
        \sqrt{r} B(\frac{r}{2}, \frac{1}{2})
    \end{equation*}
    Finally the normalization factor has to be
    \begin{equation*}
        \frac{\Gamma(\frac{r+1}{2})}{\sqrt{r} \Gamma(\frac{r}{2}) \Gamma(\frac{1}{2})}
    \end{equation*}

\end{proof}

\end{document}